\documentclass[12pt]{article}
\usepackage[russian]{babel}
\usepackage{indentfirst}
\usepackage{mathtools}
\usepackage[left=2cm, right=2cm, top=2cm, bottom=2cm, bindingoffset=0cm]
{geometry}

\begin{document}

\par \textbf{Белоброцкий Денис 4 курс 5 группа}
\begin{center}
Лабораторная работа №1 
\end{center} 
\begin{center}
\textbf{Моделирование БСВ}
\end{center} 
\begin{center}
Вариант 2
\end{center}

\begin{enumerate}
\item Осуществить моделирование $ n = 1000 $ реализаций БСВ с помощью мультипликативного конгруэнтного метода (МКМ) с параметрами $ \alpha_{0} = \beta = 79507, M = 2^{31} $
\par \textbf{Мультипликативный конгруэнтный метод} (метод вычетов) 
\\Согласно этому методу псевдослучайная последовательность реализаций $ \alpha_{1},...,\alpha_{n} $ БСВ $ \alpha $ определяется по реккурентным формулам: 
$$
\alpha_{t} = \frac{\alpha_{t}^{*}}{M}, \alpha_{t}^{*} = \lbrace \beta\alpha_{t-1}^{*} \rbrace \!\!\!\!\! \mod M (t=1,2,...),
$$
где $ \beta ,M, \alpha_{0}^{*} $ - параметры датчика (натуральные числа): $ \beta $ - множитель ($ \beta < M $), $ M $ - модуль, $ \alpha_{0}^{*} \in\lbrace 1,...,M-1 \rbrace $ - стартовое значение (нечётное число).
Операция $ y=\lbrace z \rbrace \mod M $ означает вычет числа $ z $ по модулю $ M $:
$$
y = z - M \cdot [z / M],
$$
где $ [x] $ - целая часть числа $ x $.
\\По условию $ t\in\lbrace 1,...,n \rbrace $.
\item Осуществить моделирование $ n=1000 $ реализаций БСВ с помощью метода Маклорена-Марсальи (один датчик должен быть мультипликативно конгруентный (п. 1), второй – на выбор).
$ K $ – объем вспомогательной таблицы.
\par \textbf{Метод Маклорена-Марсальи} 
\\Основан на комбинировании двух простейших программных датчиков БСВ. Оба датчика будут построены с помощью мультипликативного конгруэнтного метода.
\\Пусть $ \lbrace b_{t} \rbrace,\lbrace c_{t} \rbrace $ - псевдослучайные последовательности, порождаемые независимо работающими датчиками; $ \lbrace a_{t} \rbrace $ - результирующая псевдослучайная последовательность реализаций БСВ; $ V=\lbrace V(0), V(1),...,V(K-1) \rbrace $ - вспомогательная таблица из $ K $ чисел.
\\Процесс вычисления $\lbrace a_{t} \rbrace$ включает следующие этапы:
\begin{enumerate}
\item Первоначальное заполнение таблицы $ V $:
$$ V(i)=b_{i},i=\overline{0, K-1}; $$
\item Случайный выбор из таблицы: $$ \alpha_{t}=V(s), s=[c_{t} \cdot K]; $$
\item Обновление табличных значений:
$$ V(s) = b_{t + K}, t = 0,1,2,... \, . $$
\end{enumerate}
\newpage
\item Проверить точность моделирования обоих датчиков (п. 1 и п. 2) с помощью критерия согласия Колмогорова и $ \chi^{2} $-критерия Пирсона с уровнем значимости $ \epsilon = 0.05 $
\par \textbf{Критерий Колмогорова}
\\Данный критерий позволяет осуществить проверку гипотез в условиях, когда функция распределения $ F_{0}(x) $ модельного закона известна полностью, то есть не зависит от неизвестных параметров. Он основан на анализе мер уклонения эмпирической и модельной функций распределения.
\par Эмпирическая функция распределения по случайной выборке $ X = \lbrace x_{1},...,x_{n} \rbrace $ реализаций СВ $ \xi $ определяется по формуле:
$$
F_{n}(x) = \frac{1}{n} \sum\limits_{i=1}^{n} I_{[-\infty, x]} (x_{i}),\: I_{[-\infty, x]} (x_{i}) = 
	\begin{cases}
			1, x_{i} \leq x, \\
			0, x_{i} > x.
	\end{cases}
$$
\par Введём статистику
$$
d = \sup_{x \in R} \mid F_{0}(x) - F_{n}(x) \mid \in [0, 1]
$$
называемую расстоянием Колмогорова между $ F_{0}(x) $ и $ F_{n}(x) $.
\\Известно, что гипотеза $ H_{0} $ верна и $ n \longrightarrow \infty $, то статистика $ \sqrt[]{n} d $ имеет распределение Колмогорова с функцией распределения $ K(y) $ вида:
$$ K(y) = 1 - 2 \sum_{j=1}^{\tau} (-1)^{j - 1} \exp(-2 j^2 y^2),\; y\geq 0 .$$
\\Критерий согласия Колмогорова представляет собой следующее решающее правило:
\\принимается гипотеза 
$ 
	\begin{cases}
			H_{0},\; \sqrt[]{n} d < \Delta, \\
			H_{1},\; \sqrt[]{n} d \geq \Delta.
	\end{cases} 
$
\\Порог $ \Delta = K^{-1}(1 - \varepsilon) $ - квантиль уровня $ (1 - \varepsilon) $ распределения Колмогорова, $ \varepsilon $ - задаваемый пользователем уровень значимости.
\\В качестве модельного закона возьмем равномерное распределение с ФР:
$$
	\begin{cases}
			0, x < a, \\
			\frac{x - a}{b - a}, a \leq x < b, [a, b] = [0, 1] \\
			1, x \geq b.
	\end{cases}
$$

\par \textbf{Критерий Пирсона}
\\Данный критерий широко используется в задачах статистического анализа данных для проверки соответствия экспериментальных данных заданному модельному непрерывному или дискретному закону распределения, определяемому функцией распределения $ F_{0}(x)=F_{0}(x, \theta_{0}) $. 
\\Гипотетические вероятности попадания значений $ \xi $ в ячейки гистограммы при истинной гипотезе $ H_{0} $ и полностью заданной функции $ F_{0}(x) $ равны:
$$
p_k = P \lbrace \xi \in [x_{k - 1}, x_k) \rbrace = F_0 (x_k) - F_0 (x_{k - 1}),
$$
где $ \lbrace x_l \rbrace (l = \overline{0, K}) $ - границы ячеек гистограммы. 
\newpage
\par Статистика критерия проверки гипотез имеет вид:
\begin{equation}
\chi^2 = \sum_{k = 1}^K \frac{(\nu_k - np_k)^2}{np_k} \geq 0
\end{equation}
\\и характеризует взвешенную сумму квадратов уклонений частот $ \lbrace \nu_k \rbrace $ от гипотетических значений $ \lbrace np_k \rbrace $. Чем больше $ \chi^2 $ , тем “сильнее” выборка $ X $ не согласуется с $ H_0 $. 
\\ Статистика $ (1) $ предполагает, что гипотеза $ H_0 $ верна, $ \chi^2 $ - распределение с $ K - 1 $ степенями свободы.
\\ $ \chi^2 $ - критерий Пирсона основан на $ (1) $ и имеет вид:
\\принимается гипотеза 
$ 
	\begin{cases}
			H_{0},\; \chi^2 < \Delta, \\
			H_{1},\; \chi^2 \geq \Delta,
	\end{cases} 
$
\\где $ \Delta = 1 - F(\chi^2) $, $ F(\chi^2) $ - значение ф-ции распределения статистики $ (1) $ со степенью свободы $ K - 1 $. Значение это вычисляется с помощью какой-то функции, либо берется табличным. 

\end{enumerate}
\end{document}